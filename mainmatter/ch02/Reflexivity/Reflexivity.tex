
\section{Reflexivity}
Recall that a seminormed space X is said to be \bf reflexive \rm if $c(X)=X^{**}$. Since $X^{**}$ is always complete and c an isometry, any reflexive space is always complete.
Due to the Banach-Alaoglu theorem, in reflexive space X, the closed unit ball of X is weakly compact. For this reason and others, reflexivity is a condition of interest to many mathematicians. We begin with a basic result. 

\begin{lem}[Reflexive Separable]
    \label{lem:reflexiveseparable}
    Let X be a complete seminormed space. Then the following are equivalent. 
    \begin{enumerate}
        \item X is reflexive. 
        \item The closed unit ball of X is weakly compact. 
        \item Each closed separable subspace of X is reflexive. 
        \item All collections of closed, bounded, convex sets in X have the finite intersection property
        \item The closed unit ball of X is weakly sequentially compact
    \end{enumerate} 
    \begin{proof}$(1 \implies 2)$
        Let $X$ be reflexive. By \ref{thm:eberleinsmulian} it is sufficient to show that any sequence $\{x_i\}_{i \in \N} \subset \overline{B_X(0;1)}$ has a weak cluster point $x \in \overline{B_X(0;1)}$. Since $\overline{B_{X^{**}}(0;1)}$ is $weak^*$ compact, $\{c(x_i)\}_{i \in \N}$ has a subsequence $\{c(x_{n_i})\}_{i \in \N}$ such that $c(x_{n_i}) \overset{w^*}{\to} \tilde{x} \in \overline{B_{X^{**}}(0;1)}$. Since X is reflexive, for some $x \in \overline{B_X(0;1)}$, $c(x)= \tilde{x}$. 
        Let $x^* \in X^*$. Then, \begin{equation}
            \abs{\ip{x_{n_i}-x,x^*}} = \abs{\ip{x^*,c(x_{n_i})-\tilde{x}}} \to 0
        \end{equation}
        as $i \to \infty$, and so $x_{n_i} \overset{w}{\to} x$, completing the proof. 
    \end{proof}
    \begin{proof} $(2 \implies 3)$
        Suppose the closed unit ball of X is weakly compact, and let $x^{**} \in \overline{B_{X^{**}}(0;1)}$. By \ref{thm:goldstine}, there is a sequence $\{x_n\}_{n \in \N} \subset \overline{B_X(0;1)}$ such that $c(x_n) \overset{w^*}{\to}  x^{**}$. By assumption, there is a subsequence $\{x_{n_k}\}_{k \in \N}$ such that $x_{n_k} \overset{w}{\to} x \in \overline{B_X(0;1)}$. This implies $c(x_{n_k}) \overset{w^*}{\to} c(x)$, and so since the $weak^*$ topology is Hausdorff,  $x^{**}=c(x) \in c\pa{\overline{B_X(0;1)}}$. 
    \end{proof}
    \begin{proof} $(2 \implies 3)$. 
        Let X be reflexive and $S \subset X$ be a closed separable vector subspace. Let $\{x_i\}_{i \in \N} \subset \overline{B_X(0;1)}$. By assumption this sequence has an $X-weakly$ convergent subsequence, $x_{n_k} \to x \in X$. Since S is weakly closed, $x \in S$, and since the weak topology on X is finer than that on S, $x_{n_k} \overset{S-w}{\to} x$. By \ref{thm:eberleinsmulian} and $(2 \implies 1$, S is reflexive.  
    \end{proof} 
    \begin{proof} $(3 \implies 2)$
        Let $\{x_n\}_{n \in \N} \subset \overline{B_X(0;1)}$. Then since $S:=\overline{span\{x_i\}_{i \in \N}}$ is a closed separable subspace, $\{x_n\}_{n \in \N}$ has an S-weakly convergent subsequence, $x_{n_k} \overset{S-w}{\to} x \in S$.  
        If $x^* \in X^*$, then $x^*|_{S} \in S^*$, so that $\abs{\ip{x-x_{n_k},x^*}} \to 0$, implying $x_{n_k} \overset{w}{\to} x$, an application of \ref{thm:eberleinsmulian} finishes the proof. 
    \end{proof} 
    \begin{proof} $(4 \iff 2)$
        Obvious since closed convex sets are weakly closed. 
    \end{proof} 
    \begin{proof} $(5 \iff 2)$ 
        Apply \ref{thm:eberleinsmulian}.
    \end{proof} 
\end{lem} 

\subsection{James}
As an easy application of \ref{thm:banachalaoglu} and \ref{thm:eberleinsmulian}, for a reflexive space X, all $x^* \in X^*$ attain their norm.  The converse of this fact was, for a time, an open question of considerable interest. The converse of this result was, as is traditional in mathematics, proven in a piecemeal manner. The result was first tackled by James in \cite{james50} under the added assumption that every space Y isomorphic to X has the property that each $y^* \in Y^*$ attains its norm and that X permits a Shauder basis. This result was rapidly improved by Klee in \cite{klee50} who dropped the assumption of a Schauder basis, and then by James again in \cite{james57} who proved the result in the case of a separable space X. The question of the converse in a Banach space was finally answered to the affirmative in \cite{james64reflexivity}, building on the arguments in \cite{james57}. This paper included generalizations all the way to quasi-complete locally convex TVS's. 

\begin{df}
    If X is a topological vector space and $\{x_i^*\}_{i \in \N} \subset X^*$, then $CoLim\{x_i^*\}_{i \in \N}$ is the set of all $x^* \in X^*$ such that for every $x \in X$,
    \begin{equation}
        \liminf\limits_{i \to \infty} \ip{x,x_i^*} \leq  \ip{x,x^*} \leq \limsup\limits_{i \to \infty} \ip{x,x_i^*}
    \end{equation}
\end{df} 
\begin{rmk}[CoLim Nonempty]
    \label{rmk:colimnonempty}
    Let X be a complete seminormed space and let $\{x_i^*\}_{i \in \N} \subset X^*$ be bounded. Then $CoLim\{x_i^*\}_{i \in \N} \neq \emptyset$
    \begin{proof}
        Since $\{x_i^*\}_{i \in \N}$ is bounded, it has a subsequence with a $weak^*$ limit $x^*$ who must live in $CoLim\{x_i^*\}_{i \in \N}$.
    \end{proof} 
\end{rmk} 
\begin{lem}
    \label{lem:james}
    Let X be a complete seminormed space, $\alpha \in (0,1)$, $\{x_i^*\}_{i \in \N} \subset X^*$, and $\{\beta_i\}_{i \in \N} \subset (0,1)$ such that $\sum_{i \in \N} \beta_i=1$. Then if (1) or (3) hold below, there are $\{y_i^*\}_{i \in \N} \subset X^*$ and $\gamma \geq \alpha$ such that $(2)$ or $(4)$ hold respectively. 
    \begin{enumerate}
        \item $\{x_i^*\}_{i \in \N} \subset \partial B_{X^{*}}(0;1)$ such that $d\pa{ 0, \overline{co}\{x_i^*\}_{i \in \N}} \geq \alpha$.
        \item $\gamma \leq 1$, and for each $i \in \N$, 
        \begin{equation}
            y_i^* \in \overline{co}\{x_j^*\}_{j \geq i} \tab[1cm] \norm{\sum_{j \in \N} \beta_j y_j^*}=\gamma \tab[1cm] \norm{\sum_{j=1}^i \beta_j y_j^*} < \gamma \pa{1-\alpha \pa{\sum_{j=i+1}^{\infty} \beta_j}}
        \end{equation}
        \item $\{x_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ such that $d\pa{ \overline{co}\{x_i^*\}_{i \in \N}-CoLim\{x_i^*\}_{i \in \N},0} \geq \alpha$.  
        \item $\gamma \leq 2$, $\{y_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$, and for each $i \in \N$, $y^* \in CoLim\{y_i^*\}_{i \in \N}$, 
        \begin{equation}
            \norm{\sum_{j \in \N} \beta_j \pa{ y_j^*-y^*}}=\gamma \tab[1cm] \norm{\sum_{j=1}^i \beta_j\pa{y_j^*-y^*}} < \gamma \pa{1-\alpha \pa{ \sum_{j=i+1}^{\infty} \beta_j}}
        \end{equation}
    \end{enumerate} 
    \begin{proof} $(1 \implies 2)$
        There exists a positive sequence $\{\delta_i\}_{i \in \N}$ such that 
        \begin{equation} 
            \sum_{i \in \N} \frac{\beta_i \delta_i}{\pa{ \sum\limits_{j=i+1}^{\infty} \beta_i} \pa{ \sum\limits_{j=i}^{\infty} \beta_i}} < 1-\alpha
        \end{equation} 
        Let $\gamma_1 \in \R$ and choose $y_1^* \in \overline{co}\{x_i^*\}_{i \in \N}$ such that 
        $\gamma_1 = d\pa{0,\overline{co}\{x_i^*\}_{i \in \N}}$
        and
        $\norm{y_1^*} \leq \gamma_1\pa{1+\delta_1}$.
        From here, for each $n \geq 1$, define $\gamma_{n+1}\in \R$ and choose $y_{n+1}^* \in \overline{co}\{x_i^*\}_{i \geq n+1}$ such that  
        \begin{equation}
            \gamma_{n+1}=\inf\left\{ \norm{\pa{\sum_{i=1}^n \beta_i y_i^*}+ \pa{1-\sum_{i=1}^n \beta_i}y^*}: y^* \in \overline{co}\{x_i^*\}_{i \geq {n+1}}\right\}
        \end{equation}
        and 
        \begin{equation}\norm{\sum_{i=1}^n \beta_i y_i^* + \pa{ 1- \sum_{i=1}^n \beta_i } y_{n+1}^*} < \gamma_{n+1} \pa{1+\delta_{n+1}}
        \end{equation}
        It is clear that since the set over which we are taking the infimum never gets larger, so $\{\gamma_i\}_{i \in \N}$ is a nondecreasing sequence. Further, since $\{x_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ and $\sum_{i \in \N} \beta_i=1$, we have, for every i, 
        \begin{equation}
            \alpha \leq \gamma_i \nearrow \gamma = \norm{\sum_{k \in \N} \beta_k y_k^*} \leq 1
        \end{equation}
        So what is left to be shown is that for every $i \in \N$, 
        \begin{equation}
            \norm{\sum_{j=1}^i \beta_j y_j^*} < \gamma \pa{1-\alpha \pa{ \sum_{j=i+1}^\infty \beta_j}}
        \end{equation}
        Let $i \in \N$. Then, 
        \begin{equation}
            \begin{split}
                \norm{\sum_{j=1}^i \beta_j (y_j^*-y^*)} & = \norm{ \pa{\pa{ \frac{\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}} \pa{\sum_{j=1}^{i-1} \beta_j y_j^*}}+ \pa{\pa{ \frac{\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}}\pa{\beta_i y_i^*}}}\\
                & = \norm{ \pa{\pa{ \frac{\lambda_i+\sum_{j=i+1}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}} \pa{\sum_{j=1}^{i-1} \beta_j y_j^*}}+ \pa{\pa{ \frac{\beta_i\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}}\pa{ y_i^*}}}\\
                & \leq \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \norm{ \sum_{j=1}^{i=1} \beta_j y_j^*+ \pa{ \sum_{j=i}^\infty \beta_j} y_i^*}+ \frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} \norm{\sum_{j=1}^{i-1} \beta_j y_j^*}\\
                & \leq \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \norm{ \sum_{j=1}^{i=1} \beta_j y_j^*+ \pa{ 1-\sum_{j=1}^{i-1} \beta_j} y_i^*}+ \frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} \norm{\sum_{j=1}^{i-1} \beta_j y_j^*}\\
                & < \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \pa{\gamma_i}\pa{1+\delta_i}+\frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} \norm{\sum_{j=1}^{i-1} \beta_j y_j^*}\\
                & = \pa{ \sum_{j=i+1}^{\infty} \beta_j} \pa{ \pa{ \frac{\beta_i \gamma_i \pa{1+\delta_i}}{\pa{\sum_{j=i}^\infty \beta_j}\pa{\sum_{j=i+1}^\infty \beta_j}}}+ \pa{\frac{1}{\sum_{j=i}^\infty \beta_j}} \norm{\sum_{j=1}^{i-1} \beta_j y_j^*}}
            \end{split}
        \end{equation}
        Hence, for any $i \in \N$, 
        \begin{equation}
            \begin{split}
                \norm{\sum_{j=1}^i \beta_j y_j^*} & < \pa{\sum_{j=i+1}^\infty \beta_j} \pa{ \pa{ \frac{\beta_i\gamma_i\pa{1+\delta_i}}{\pa{\sum_{j=i}^\infty \beta_j}\pa{ \sum_{j=i+1}^\infty \beta_j}}} + \pa{\frac{1}{\sum_{j=i}^\infty \beta_j}} \norm{\sum_{j=1}^{i-1} \beta_j y_j^*}}\\
                & < \pa{\sum_{j=i+1}^{\infty} \beta_j} \sum_{j=1}^i \frac{\beta_j \gamma_j\pa{1+\delta_j}}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}\\
                & \leq \gamma \pa{\sum_{j=i+1}^{\infty} \beta_j} \sum_{j=1}^i \frac{\beta_j \pa{1+\delta_j}}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}\\
                &\leq \gamma \pa{ \sum_{j=i+1}^\infty \beta_j}\pa{ \pa{ \sum_{j=1}^i \frac{\beta_j}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}}+ \pa{1-\alpha}}\\
                & = \gamma \pa{ \sum_{j=i+1}^\infty \beta_j}\pa{ \pa{ \sum_{j=1}^i\pa{\frac{1}{\sum_{k=j}^\infty \beta_k}-\frac{1}{\sum_{k=j+1}^\infty \beta_k}}}+ \pa{1-\alpha}}\\
                & = \gamma\pa{\sum_{j=i+1}^\infty \beta_j} \pa{ \frac{1}{\sum_{j=i+1}^\infty \beta_j} - \frac{1}{\sum_{j=1}^{\infty} \beta_j}+1-\alpha}\\
                &=\gamma \pa{ \sum_{j=i+1}^\infty \beta_j} \pa{ \frac{1}{\sum_{j=i+1}^\infty \beta_j}- \alpha}\\
                & = \gamma \pa{ 1- \alpha \pa{\sum_{j=i+1}^\infty \beta_j}}
            \end{split} 
        \end{equation}
        completing the proof.
    \end{proof}
    \begin{proof} $(3 \implies 4)$
        There exists a positive sequence $\{\delta_i\}_{i \in \N}$ such that 
        \begin{equation} 
            \sum_{i \in \N} \frac{\beta_i \delta_i}{\pa{ \sum\limits_{j=i+1}^{\infty} \beta_i} \pa{ \sum\limits_{j=i}^{\infty} \beta_i}} < 1-\alpha
        \end{equation} 
        Define $\{x_i^0\}_{i \in \N} = \{x_i^*\}_{i \in \N}$, 
        \begin{equation}
            \gamma_1 = \inf\left\{ \sup\limits_{y^* \in CoLim\{\phi_i\}_{ i\in \N}} \left\{ \norm{x^*-y^*}\right\} : x^* \in \overline{co}\{x_i^*\}_{i \in \N}, \phi_k \in \overline{co}\{x_i^*\}_{i \geq k}, k \in \N \right\}
        \end{equation}
        and pick $y_1^* \in \overline{co}\{x_i^*\}_{i \in \N}$, $\{\phi_i^1\}_{i \in \N} \subset X^*$ such that $\phi_k^1 \in \overline{co}\{x_i^*\}_{i \geq k}$ for every k and $w'
        \in CoLim\{\phi_i^1\}_{i \in \N}$ such that 
        \begin{equation} 
            \gamma_1(1-\delta_1) < \norm{y_1^*-w} < \gamma_1(1+\delta_1)
        \end{equation}
        So that there exists $\tilde{x} \in \overline{B_X(0;1)}$ such that $\gamma_1 \pa{1-\delta_1} < \ip{\tilde{x},y_1^*-w'}$, and since $w' \in CoLim\{\phi_i^1\}_{i \in \N}$, we extract a subsequence $\{x_i^1\}_{i \in \N}$ of $\{\phi_i^1\}_{i \in \N}$  so that for any $w \in CoLim\{x_i^1\}_{i \in \N}$, we have 
        \begin{equation}
            \ip{\tilde{x},w} = \lim\limits_{i \to \infty} \ip{\tilde{x},x_i^1} = \liminf\limits_{i \to \infty} \ip{\tilde{x},\phi_i^1} \leq \ip{\tilde{x},w'}
        \end{equation}
        And so, for any $w \in CoLim\{x_i^1\}_{i \in \N}$, we have
        \begin{equation} 
            \gamma_1  \pa{1-\delta_1} < \ip{\tilde{x},y_1^*-w}
        \end{equation}
        Continuing inductively, for $i \in \N$, set 
        \begin{equation}
            \gamma_{i+1}= \inf \left\{ \sup \left\{ \norm{\pa{\sum_{j=1}^{i} \beta_j y_j^*} + \pa{\pa{\sum_{j=i+1}^{\infty}\beta_j }y^*}-w}: w \in CoLim\{\phi_i\}_{i \in\N}\right\}\right\}
        \end{equation}
        Where the infimum is taken over all $y^* \in \overline{co}\{x_j^{i}\}_{j \geq i+1}$ and all $\{\phi_i\}_{i \in \N} \subset X^*$ such that $\phi_k \in \overline{co} \{x_j^i\}_{j \geq k}$. 
        Next, pick $y_{i+1}^* \in \overline{co}\{x_j^i\}_{j \geq i+1}$ and $\{\phi_j^{i+1}\}_{j \in \N} \subset X^*$ such that for every k, $\phi_k^{i+1} \in \overline{co}\{x_j^i\}_{j \geq k}$ and pick $w' \in CoLim\{\phi_j^{i+1}\}_{j \in \N}$ such that
        \begin{equation}
            \gamma_{i+1}(1-\delta_{i=1}) < \norm{ \sum_{j=1}^i \beta_j y_j^*+ \pa{ \sum_{j=i+1}^{\infty} \beta_j} y_{i+1}^*-w'} < \gamma_{i+1}\pa{1+\delta_{i+1}}
        \end{equation}
        Next, pick $\tilde{x} \in \overline{B_X(0;1)}$ satisfying
        \begin{equation}
            \gamma_{i+1}(1-\delta_{i+1}) < \ip{\tilde{x}, \sum_{j=1}^i \beta_j y_j^*+ \pa{ \pa{ \sum_{j=i+1}^\infty \beta_j} y_j^*}-w'}
        \end{equation}
        and apply the fact that since $\liminf\limits_{j \to \infty} \ip{\tilde{x},\phi_j^{i+1}} \leq \ip{\tilde{x},w}$, we can find a subsequence $\{x_j^{i+1}\}_{j \in \N}$ of $\{\phi_j^{i+1}\}_{j \in \N}$ such that for every $w \in CoLim\{x_j^{i+1}\}_{j \in \N}$ we have 
        \begin{equation}
            \gamma_{i+1}(1-\delta_{i+1}) < \ip{\tilde{x}, \sum_{j=1}^i \beta_j y_j^*+ \pa{ \pa{ \sum_{j=i+1}^\infty \beta_j} y_j^*}-w}
        \end{equation}
        completing our construction. 
        Clearly, $CoLim\{y_j^*\}_{j \in \N} \subset CoLim\{\phi_j^i\}_{j \in \N}$ for every $i \in \N$. Hence, for every $w \in CoLim\{y_j^*\}_{ j\in \N}$, for ever $i \in \N$, we have 
        \begin{equation}
            \gamma_i(1-\delta_i) < \norm{\sum_{j=1}^{i-1} \beta_j y_j^*+ \pa{\pa{\sum_{j=i}^\infty \beta_j} y_i^*}-w} < \gamma_i(1-\delta_i)
        \end{equation}
        Also, since $\{y_j^*\}_{j \in \N} \subset \overline{co}\{x_j\}_{j \in \N} \subset \overline{B_{X^*}(0;1)}$, $CoLim\{y_j^*\}_{j \in \N} \subset \overline{co}\{y_j^*\}_{j \in \N} \subset \overline{B_{X^*}(0;1)}$.
        By definition, $\gamma_1 \geq \alpha$, and
        $\{\gamma_i\}_{i \in \N}$ is a nondecreasing sequence since it is defined by taking the infimum over a set which never gains new elements as $i$ increases. Further, $\norm{w} \leq 1$ for $w \in CoLim\{y_j^*\}_{j \in \N}$ implies that for every $n$, $\gamma_n \leq 2$, so by monotone convergence, $\gamma_i \nearrow \gamma= \norm{\sum_{j \in \N}\beta_j \pa{y_j-w}}\leq 2$. 
        As for the final estimate, we have, for $i \in \N$ and $y^* \in CoLim\{y_j^*\}_{j \in \N}$, we have 
        
        Let $i \in \N$. Then, 
        %\begin{align}
        %\norm{\sum_{j=1}^i \beta_j (y_j^*-y^*)} & = \norm{ \pa{\pa{ \frac{\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}} \pa{\sum_{j=1}^{i-1} \beta_j %(y_j^*-y^*)}}+ \pa{\pa{ \frac{\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}}\pa{\beta_i (y_i^*-y^*)}}}\\
        %& = \norm{ \pa{\pa{ \frac{\lambda_i+\sum_{j=i+1}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}} \pa{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}}\\
        %& \tab[1cm] + \pa{\pa{ \frac{\beta_i\sum_{j=i}^\infty \beta_j}{\sum_{j=i}^\infty \beta_j}}\pa{ (y_i^*-y^*)}}}HOWDOIBRINGTHISNORMDOWN\\
        %& \leq \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \norm{ \sum_{j=1}^{i=1} \beta_j (y_j^*-y^*)+ \pa{ \sum_{j=i}^\infty \beta_j} (y_i^*-y^*)}\\
        %& \tab[1cm] + \frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} \norm{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}\\
        %& \leq \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \norm{ \sum_{j=1}^{i=1} \beta_j (y_j^*-y^*)+ \pa{ 1-\sum_{j=1}^{i-1} \beta_j} (y_i^*-y^*)}\\
        %& \tab[1cm] + \frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} \norm{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}\\
        %& < \frac{\beta_i}{\sum_{j=i}^{\infty} \beta_j} \pa{\gamma_i}\pa{1+\delta_i}+\frac{\sum_{j=i+1}^{\infty} \beta_j}{\sum_{j=i}^{\infty} \beta_j} %\norm{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}\\
        %& = \pa{ \sum_{j=i+1}^{\infty} \beta_j} \pa{ \pa{ \frac{\beta_i \gamma_i \pa{1+\delta_i}}{\pa{\sum_{j=i}^\infty \beta_j}\pa{\sum_{j=i+1}^\infty \beta_j}}}+ %\pa{\frac{1}{\sum_{j=i}^\infty \beta_j}}\\ 
        %& \tab[1cm] *\norm{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}}
        %\end{align}
        Hence, for every $i \in \N$, we have 
        \begin{equation}
            \begin{split}
                \norm{\sum_{j=1}^i \beta_j (y_j^*-y^*)} & < \pa{\sum_{j=i+1}^\infty \beta_j} \\
                & \tab[.5cm]*\pa{ \pa{ \frac{\beta_i\gamma_i\pa{1+\delta_i}}{\pa{\sum_{j=i}^\infty \beta_j}\pa{ \sum_{j=i+1}^\infty \beta_j}}} + \pa{\frac{1}{\sum_{j=i}^\infty \beta_j}} \norm{\sum_{j=1}^{i-1} \beta_j (y_j^*-y^*)}}\\
                & < \pa{\sum_{j=i+1}^{\infty} \beta_j} \sum_{j=1}^i \frac{\beta_j \gamma_j\pa{1+\delta_j}}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}\\
                & \leq \gamma \pa{\sum_{j=i+1}^{\infty} \beta_j} \sum_{j=1}^i \frac{\beta_j \pa{1+\delta_j}}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}\\
                &\leq \gamma \pa{ \sum_{j=i+1}^\infty \beta_j}\pa{ \pa{ \sum_{j=1}^i \frac{\beta_j}{\pa{\sum_{k=j}^\infty \beta_k}\pa{ \sum_{k=j+1}^\infty \beta_k}}}+ \pa{1-\alpha}}\\
                & = \gamma \pa{ \sum_{j=i+1}^\infty \beta_j}\pa{ \pa{ \sum_{j=1}^i\pa{\frac{1}{\sum_{k=j}^\infty \beta_k}-\frac{1}{\sum_{k=j+1}^\infty \beta_k}}}+ \pa{1-\alpha}}\\
                & = \gamma\pa{\sum_{j=i+1}^\infty \beta_j} \pa{ \frac{1}{\sum_{j=i+1}^\infty \beta_j} - \frac{1}{\sum_{j=1}^{\infty} \beta_j}+1-\alpha}\\
                &=\gamma \pa{ \sum_{j=i+1}^\infty \beta_j} \pa{ \frac{1}{\sum_{j=i+1}^\infty \beta_j}- \alpha}\\
                & = \gamma \pa{ 1- \alpha \pa{\sum_{j=i+1}^\infty \beta_j}}
            \end{split} 
        \end{equation}
    \end{proof} 
\end{lem}
It is worth noting that in the following two theorems, the assumption of completeness is necessary, as demonstrated by \cite{james71}.
\begin{thm}[James Separable]
    \label{thm:jamesseparable}
    If X is a separable complete seminormed space then the following are equivalent. 
    \begin{enumerate}
        \item X is not reflexive. 
        \item For every $\alpha \in (0,1)$ there is  some sequence $\{x_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ satisfying $d\pa{0,\overline{co}\{x_i^*\}_{i \in \N}} \geq \alpha$ and $x_i^* \overset{w^*}{\to} 0$. 
        \item For every $\alpha \in (0,1)$ and $\{\beta_i\}_{i \in \N} \subset (0,1)$ satisfying $\sum_{i \in \N} \beta_i = 1$, there is a $\gamma \in [0,1]$ and $\{y_i^*\}_{i \in \N} \subset X^*$ such that $y_i^* \overset{w^*}{\to} 0$ and for each $i \in \N$, 
        \begin{equation}
            \norm{\sum_{j \in \N} \beta_j y_j^*} = \gamma \tab[1cm] \norm{\sum_{j=1}^i \beta_j y_j^*} \leq \gamma \pa{ 1- \alpha \pa{ \sum_{j=i+1}^{\infty} \beta_j}}
        \end{equation}
        \item There exists $x^* \in X^*$ not achieving its norm. 
    \end{enumerate} 
    \begin{proof} $(1 \implies 2)$
        Let $\alpha \in (0,1)$. Since X is nonreflexive and $c(X)$ is complete, by Riesz's lemma \cite{kreyszig89},  there exists an $x^{**} \in B_{X^{**}}(0;1)$ such that $d(x^{**},c(X)) > \alpha$. 
        Since X is separable it has a countable dense set $\{x_i\}_{i \in \N}$. 
        Fix $i \in \N$, let $\alpha_1=\alpha_2=\cdots=\alpha_{i-1}=0$, $\alpha_i=\alpha$, and let $\{\beta_j\}_{j=1}^i \subset \C$ where $\beta_i \neq 0$ without loss of generality. Then, since c(X) is a subspace,  
        \begin{equation}
            \begin{split}
                \abs{\sum_{j=1}^i \beta_j \alpha_j}&= \abs{\beta_i \alpha_i} = \abs{\beta_i} \alpha \\
                & \leq \frac{\abs{\beta_i} \alpha}{d\pa{x^{**},c(X)}} \norm{x^{**}+ \sum_{j=1}^{i-1} \frac{\beta_j}{\beta_i}c(x_j)}\\
                & = \frac{\alpha}{d\pa{x^{**},c(X)}} \norm{\beta_i x^{**} + \sum_{j=1}^{i-1} \beta_j c(x_j)}
            \end{split}
        \end{equation}
        Since $\alpha < d\pa{x^{**}, c(X)}$, for some $\epsilon > 0$, $\epsilon + \frac{\alpha}{d\pa{x^{**},c(X)}}<1$, so by \ref{thm:helly}, since $X^{**}=\pa{X^*}^*$, there exists an $x_i^* \in \overline{B_{X^*}(0;1)}$ such that for $1 \leq j \leq i-1$ we have $\ip{x_j,x_i^*}=\ip{x_i^*,c(x_j)} = 0$ and $\ip{x_i^*,c(x_i)} \geq \alpha$.
        Using this method we construct a sequence $\{x_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ such that for each $1 \leq j \leq i-1$, $\ip{x_j,x_i^*} = 0$ and $\ip{x_i,x^{**}} \geq \alpha$. Without loss of generality, we let $\norm{x_i^*} = 1$.  Density of $\{x_j\}_{j \in \N}$ and the boundedness of $\{x_j^*\}_{j \in \N}$ implies $x_j^* \overset{w^*}{\to} 0.$
        Furthermore, any convex combination of the $(x_i^*)'s$ satisfies \begin{equation}
            \alpha \leq \ip{\sum_{j=1}^n \lambda_j x_{k_j}^*, x^{**}}\leq \norm{x^{**}} \norm{\sum_{j=1}^n \lambda_j x_{k_j}^*} \leq \norm{\sum_{j=1}^n \lambda_j x_{k_j}^*}
        \end{equation}
        so that $d\pa{0,\overline{co}\{x_i^*\}_{i \in \N}} \geq \alpha$, completing the proof. \end{proof}
    \begin{proof} $(2 \implies 3)$. 
        This is a direct application of \ref{lem:james} part $(1 \implies 2)$, paired with the fact that if for every i, $y_i^* \in \overline{co}\{x_j^*\}_{j \geq i}$ and $x_j^* \overset{w^*}{\to} x$, then $y_j^* \overset{w^*}{\to} x$. 
    \end{proof} 
    \begin{proof} $(3 \implies 4)$.
        Let $x^* = \sum_{j \in \N} \beta_j y_j^*$ and let $x \in \overline{B_X(0;1)}$. Since $y_j^* \overset{w^*}{\to} 0$, for some $N \in \N$, $\ip{x,y_j^*} < \gamma \alpha$ for every $j > \N$. Then
        \begin{equation}
            \begin{split}
                \abs{\ip{x, x^*}} & \leq \abs{ \ip{x,\sum_{j=1}^N \beta_j y_j^*}} + \abs{\ip{x,\sum_{j=N+1}^{\infty} \beta_j y_j^*}}\\
                & < \abs{\ip{x,\sum_{j=1}^N \beta_j y_j^*}} + \alpha \gamma \sum_{j=N+1}^{\infty} \beta_j\\
                & \leq \norm{\sum_{j=1}^N \beta_j y_j^*} + \alpha \gamma \sum_{j=N+1}^\infty \beta_j \leq \gamma \pa{1-\alpha \sum_{j=N+1}^\infty \beta_j}+ \gamma \alpha \sum_{j=N+1}^\infty \beta_j \\
                &= \gamma = \norm{\sum_{j \in \N} \beta_j y_j^*} = \norm{x^*}
            \end{split}
        \end{equation}
        Since the inequality is strict and $x \in \overline{B_X(0;1)}$ was arbitrary, we are done. 
    \end{proof} 
    \begin{proof} $(4 \implies 1)$. 
        If X is reflexive and $x^* \in X$, then there is a sequence $\{x_n\}_{n \in \N} \subset \overline{B_X(0;1)}$ such that $\ip{x_n,x^*} \to \norm{x^*}$.  By  \ref{lem:reflexiveseparable}, $\{x_n\}_{n \in \N}$ has a subsequence $x_{k_n} \overset{w}{\to} x \in \overline{B_X(0;1)}$. This x satisfies $\ip{x,x^*} = \norm{x^*}$. 
    \end{proof} 
\end{thm} 

\begin{thm}[James]
    \label{thm:james}
    If X is a complete seminormed space, then the following are equivalent. 
    \begin{enumerate}
        \item X is non-reflexive. 
        \item For each $\alpha \in (0,1)$, there exists an $\{x_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ and a subspace $Y \subset X$ such that $d\pa{ \overline{co}\{x_i^*\}_{i \in \N}-Y^{\perp},0} \geq \alpha$ and that $\ip{y,x_i^*} \to 0$ for each $y \in Y$.
        \item For every $\alpha \in (0,1)$ and $\{\beta_i\}_{i \in \N} \subset [0,\infty)$ such that $\sum_{i \in \N} \beta_i = 1$, there is a $\gamma \in [0,2]$ and  $\{y_i^*\}_{i \in \N} \subset \overline{B_{X^*}(0;1)}$ such that for each $y^* \in CoLim\{y_i^*\}_{i \in \N}$, each $i \in \N$, 
        \begin{equation} 
            \norm{\sum_{j \in \N} \beta_j \pa{ y_j^*-y^*}} = \gamma \tab[1cm] \norm{\sum_{j=1}^i \beta_j \pa{ y_j^*-y_j}} < \gamma \pa{1-\alpha \pa{ \sum_{j=i+1}^{\infty} \beta_j}}
        \end{equation}
        \item There exists $x^* \in X^*$ which doesn't achieve its norm.  
    \end{enumerate}
    \begin{proof} $(1 \implies 2)$
        If X is non-reflexive, then X contains a non-reflexive closed separable subspace S. An application of \ref{thm:jamesseparable} implies the existence of a sequence $\{x_i\}_{i \in \N} \subset \overline{B_{S^*}(0;1)}$ such that 
        \begin{equation}
            d_s\pa{0,\overline{co}\{x_i\}_{i \in \N}} \geq \alpha \tab[1cm] x_i \overset{S-w^*}{\to} 0
        \end{equation}
        
        If $y^{\perp} \in X^*$ such that $Y \subset kern(y^*)$, then letting for each $i \in \N$ $x_i^*$ be a Hahn-Banach extension living in $\overline{B_X^*(0;1)}$, and let $x^* \in \overline{co}\{x_i^*\}_{i \in \N}$. Then $x:=x^*|_{S} \in \overline{co}\{x_i\}_{i \in \N}$. If $y \in Y$, then 
        $\ip{y,x_i^*}=\ip{y,x} \to 0$.
        If $y^{\perp} \in Y^{\perp}$, then 
        \begin{equation}
            \norm{x^*-y^{\perp}} \geq \norm{x-\pa{y^{\perp}|_S}}_S = \norm{x} \geq \alpha
        \end{equation}
        so $d\pa{ \overline{co}\{x_i^*\}_{i \in \N}-Y^{\perp},0} \geq \alpha$
    \end{proof}
    \begin{proof} $(2 \implies 3)$
        Since $CoLim\{x_i^*\}_{i \in \N} \subset Y^{\perp}$ from the previous part, this is an easy application of \ref{lem:james} $(3 \implies 4)$. 
    \end{proof}
    \begin{proof} $(3 \implies 4)$
        Define $\eta=\frac{\alpha^2}{4}$, and then let $\lambda_1 \in [0,\infty)$ such that for every natural n, $\lambda_{n+1} <\eta \lambda_n$ and $\sum_{k \in \N} \lambda_k = 1$.
        Let $y^* \in CoLim\{y_i^*\}_{i \in \N}$ where $\{y_i^*\}_{i \in \N}$ are as in part (3) of this theorem. Let $x \in \overline{B_X(0;1)}$. Since $y^* \in Colim\{y_i^*\}_{i \in \N}$, and since $\alpha \leq \gamma$, there exists $i \in \N$ such that 
        \begin{equation}
            \ip{x,y_{i+1}^*-y^*} < \alpha^2 - 2\eta \leq \alpha \gamma - 2 \eta
        \end{equation}
        For this x, we have 
        \begin{equation}
            \begin{split}
                \ip{x, \sum_{j \in \N} \beta_j (y_j^*-y^*)}& < \sum_{j=1}^i \beta_j \ip{x,y_j^*-y^*}+ \beta_{i+1} \pa{\alpha \gamma - 2 \eta} + \sum_{j=i+2}^{\infty} \beta_j \ip{x,y_j^*-y^*}\\
                & \leq \norm{\sum_{j=1}^i \beta_j(y_j^*-y^*)}+ \beta_{i+1} \pa{\alpha \gamma -2\eta}+ 2 \sum_{j=i+2}^{\infty} \beta_j\\
                & \leq \gamma \pa{1-\alpha \pa{\sum_{j=i+1}^{\infty} \beta_j}}+ \beta_{i+1}(\alpha \gamma -2\eta)+ 2 \sum_{j=i+2}^{\infty} \beta_j\\
                & = \gamma -\gamma \alpha \sum_{j=i+2}^{\infty} \beta_j-2 \eta \beta_{i+1} + 2 \sum_{j=i+1}^{\infty} \eta \beta_j\\
                & \leq \gamma - \pa{\gamma \alpha - 2 \eta} \sum_{j=i+1}^{\infty} \beta_j < \gamma = \norm{\sum_{j \in \N} \beta_j \pa{y_j^*-y^*}}
            \end{split}
        \end{equation}
        Since $x \in \overline{B_X(0;1)}$ was arbitrary, we are done. 
    \end{proof}
    \begin{proof} $(4 \implies 1)$
        If X is reflexive and $x^* \in X$, then there is a sequence $\{x_n\}_{n \in \N} \subset \overline{B_X(0;1)}$ such that $\ip{x_n,x^*} \to \norm{x^*}$.  By  \ref{lem:reflexiveseparable}, $\{x_n\}_{n \in \N}$ has a subsequence $x_{k_n} \overset{w}{\to} x \in \overline{B_X(0;1)}$. This x satisfies $\ip{x,x^*} = \norm{x^*}$. 
    \end{proof} 
\end{thm} 

\begin{cor} Let X be a complete seminormed  space. Then the following are equivalent. 
    \begin{enumerate}
        \item X is reflexive.
        \item Each element of $X^*$ attains its norm. 
    \end{enumerate}
    \begin{proof}
        Direct consequence of \ref{thm:james}.
    \end{proof} 
\end{cor} 




\subsection{Lindenstrauss On Nonseparable Reflexive Banach Spaces}
If $\Gamma \neq \emptyset$, then $c_0(\Gamma)$ denotes the space of mappings $f:\Gamma \to \C$ such that for every $\epsilon > 0$, $card\left\{x \in \Gamma : |f(x)|>\epsilon\right\} \in \N$. 
