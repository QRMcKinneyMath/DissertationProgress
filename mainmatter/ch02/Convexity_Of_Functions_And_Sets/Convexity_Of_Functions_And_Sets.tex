
\section{Convexity Of Functions And Sets}
\begin{df}[Convex Functions]
    \label{df:convexfunction}
    Let $X$ be a vector space, Y a topological vector space, $\scU$ the set of neighborhoods of 0 in Y except Y itself, $f:X \to (-\infty,\infty]$, and $g:Y \to (-\infty,\infty]$.
    Let $x,y \in X$. 
    \begin{enumerate}
        \item We call $D(f):= f^{-1}\pa{\R}$ the \bf effective domain \rm of $f$. 
        \item If $D(f) \neq \emptyset$, then we call $f$ \bf proper.\rm
        \item We call $Epi\pa{f} :=\{ (x,t) \in X \times \R : f(x) \leq t \}$ the \bf Epigraph \rm of $f$. 
        \item We denote $[x,y] = \{tx+(1-t)y: t \in [0,1]\}$.
        \item We denote $(x,y)=\{tx+(1-t)y: t \in (0,1)\}$.
        \item We say that $C\subset X$ is \bf convex \rm if $[x,y] \subset C$ for each $x,y \in C$. 
        \item We say that $C \subset X$ is \bf strictly convex \rm if for each $x,y \in C$, for each $z_0 \in (x,y)$, and for each $z_1 \in X$, there is a $t > 0$ such that $[z_0,z_0+tz_1] \subset C$. 
        \item We say that $f$ is \bf convex \rm if for each $x,y \in X$, $f\pa{\frac{x+y}{2}} \leq \frac{f(x)+f(y)}{2}$. 
        \item We say that $f$ is \bf strictly convex \rm if for each $x,y \in X$, $f\pa{\frac{x+y}{2}} < \frac{f(x)+f(y)}{2}$. 
        \item If g is a convex function, then then we define the \bf modulus of local uniform convexity \rm of g, $\tilde{\Delta}:\scU \times Y\to \R$ by
        \begin{equation}
            \tilde{\Delta} \pa{U, x} = \frac{1}{2} \inf\limits_{y \in Y \setminus (x+U)} \left\{ f(x)+f(y)-2f\pa{\frac{x+y}{2}}\right\}
        \end{equation}
        \item If g is a convex function, then we define the \bf modulus of uniform convexity \rm of g, $\Delta:\scU \to \R$ by  $\Delta(U) = \inf\limits_{g(x)=1} \tilde{\Delta}(U,x)$. 
        \item If g is a convex function, then we say that g is \bf locally uniformly convex  at \rm  $x \in Y$ if for each $U \in \scU$, $\tilde{\Delta}(U,x) > 0$. 
        \item We say that g is \bf locally uniformly convex \rm if it is \bf locally uniformly convex \rm  at each of its points. 
        \item We say that g is \bf uniformly convex \rm if for each $U \in \scU$, $\Delta(U)>0$. 
        \item We say that g is \bf lower semi-continuous\rm, or LSC if it is continuous with respect to the topology on $(-\infty, \infty]$ generated by sets of the form $(-\infty,\alpha)$ where $\alpha \in \R$, along with $(-\infty,\infty]$ itself. 
    \end{enumerate} 
\end{df} 
\begin{rmk}[Basis Independence]
    It is easy to see that a mapping is locally uniform convex at a point (locally uniformly convex) [uniformly convex] if we define $\Delta$, $\tilde{\Delta}$ in terms of a single neighborhood basis of Y at 0 instead of all neighborhoods of 0 in Y.
\end{rmk} 

\begin{rmk}[Strictly Convex Real Valued]
    \label{rmk:strictlyconvexrealvalued}If X is a vector space and $f:X \to (-\infty,\infty]$ is strictly convex, and f is finite everywhere.
    \begin{proof}
        If $f(x)= \infty$  where $x \in X$ and f is strictly convex, then we must have $\infty = f(x) < \frac{f(0)+f(2x)}{2}$, a contradiction. 
    \end{proof} 
\end{rmk} 

\begin{prop} 
    Let X be a vector space and $T:X \to (-\infty,\infty]$. Then the following are equivalent. 
    \begin{enumerate}
        \item T is (strictly) convex.
        \item For each $x_1 \neq x_2 \in X$ and $\lambda \in (0,1)$.
        \begin{equation}
            T\pa{\lambda x_1 + (1-\lambda )x_2} \pa{<} \leq \lambda Tx_1 + (1-\lambda)Tx_2
        \end{equation} 
        \item For each $\{\lambda_i\}_{i=1}^n \subset (0,1)$ which sums to 1, for each $\{x_i\}_{i=1}^n \subset X$, 
        \begin{equation}
            T\pa{\sum_{j=1}^n \lambda_j  x_j } \pa{<}\leq \sum_{j=1}^n \lambda_j Tx_j
        \end{equation}
        \item If $x_1 \neq x_3 \in X$ and $x_2 \in (x_1,x_3)$, say $x_2=\lambda x_1+(1-\lambda)x_3$ then 
        \begin{equation} 
            \frac{Tx_2-Tx_1}{\lambda} \pa{<}\leq Tx_3-Tx_1 \pa{<}\leq \frac{Tx_3-Tx_2}{1-\lambda}
        \end{equation}
        \item $Epi(T)$ is (strictly) convex
    \end{enumerate} 
    \begin{proof} $(1 \implies  2)$
        
    \end{proof}
    \begin{proof}$(2 \implies 3)$
        I utilize induction on n. 
        Since f is assumed to be (strictly) convex, the proposition holds for $n=1$ and $n=2$. 
        Let $k \in \N$.
        Suppose that for any $(\psi_1,\cdots,\psi_k)\in [0,1]^k$ such that $\sum_{j=1}^k \psi_j=1$, and for each $(x_1,\cdots,x_k) \in X^k$, we have
        \begin{equation}
            f\pa{\sum_{j=1}^k \lambda_j x_j} \pa{<}\leq \sum_{j=1}^k \lambda_j f(x_j)
        \end{equation}
        Let $(\lambda_1,\cdots,\lambda_{k+1}) \in [0,1]^{k+1}$. Let $(x_1,\cdots,x_{k+1}) \in X^{k+1}$. Without loss of generality, we assume $\lambda_{k+1} \neq 0$. 
        Then 
        \begin{equation}
            \sum_{j=1}^k \frac{\lambda_j}{1-\lambda_{k+1}}=1 \tab[1cm] \pa{\frac{\lambda_1}{1-\lambda_{k+1}},\cdots,\frac{\lambda_k}{1-\lambda_{k+1}}} \in [0,1]^k
        \end{equation}
        Hence, because f is (strictly) convex, 
        \begin{equation}
            \begin{split}
                f \pa{ \sum_{j=1}^{k+1} \lambda_j x_j} & = f\pa{ \lambda_{k+1}x_{k+1} + (1-\lambda_{k+1}) \sum_{j=1}^k \frac{\lambda_j}{1-\lambda_{k+1}} x_j}\\
                & \pa{<}\leq \lambda_{k+1} f(x_{k+1}) + (1-\lambda_{k+1}) f\pa{\sum_{j=1}^k \frac{\lambda_j}{1-\lambda_{k+1}} x_j} \\
                & \pa{<}\leq \sum_{j=1}^{k+1} \lambda_j f(x_j)
            \end{split}
        \end{equation}
    \end{proof}
    \begin{proof}$(3 \implies 4)$
    \end{proof} 
    \begin{proof} $(4 \implies 1)$. 
    \end{proof} 
    \begin{proof} $(2 \iff 5)$
    \end{proof} 
\end{prop} 
The epigraph of a function provides us with a nice characterization of lower semi-continuity. 
\begin{prop}[Convex Continuity]
    \label{prop:convexcontinuity}
    Let $X$ be a locally convex space and $f:X \to (-\infty,\infty]$. The following conditions are equivalent. 
    \begin{enumerate}
        \item f is LSC on X. %cioranescu3
        \item $Epi(f)$ is closed in $X \times \R$. 
    \end{enumerate} 
    \begin{proof}
        Define $F:X \times \R \to \tilde{\R}$ by $F(x,\alpha)=f(x)-\alpha$. 
        Then $f$ is (weakly) LSC on $X$ if and only if $F$ is (weakly) LSC on $X \times \R$. 
        Suppose $f$ is (weakly) LSC.
        Then $F$ is (weakly) LSC, so $F^{-1}((-\infty,0])=Epi(f)$ is (weakly) closed, so we're done. 
        Suppose $Epi(f)$ is (weakly) closed. 
        Then $F^{-1}((-\infty,0])$ is (weakly) closed. 
        Further, for any $\beta \in \R$, $F^{-1}((-\infty,\beta])=F^{-1}((-\infty,0])-(0,\beta)$, and so is also closed. 
        Hence $F$ is (weakly) LSC, and so $f$ is too. 
    \end{proof} 
\end{prop}
In the case of a convex function, the above proposition allows us to equate weak and strong lower semicontinuity.
\begin{cor}[Weak To Strong Convex]
    \label{cor:weaktostrongconvex}
    Let X be locally convex Hausdorff space  and $f:X \to (-\infty,\infty]$ be convex. Then $f$ is LSC if and only if it is weakly LSC. 
    \begin{proof}
        Since $Epi(f)$ is convex, it is closed if and only if it is weakly closed, allowing us to apply \ref{prop:convexcontinuity}.
    \end{proof} 
\end{cor} 
\begin{thm}[Point Continuous]
    \label{thm:pointcontinuous}
    Let X be a locally convex space and $f:X \to (-\infty,\infty]$ be convex and proper. Then $f$ is bounded on some  open set if and only if $f$ is continuous on the interior of its domain. 
    \begin{proof} $(implies)$
        Without loss of generality, we assume that f is bounded from above by M on a (weakly) open set $\scU$ which is symmetric and contains 0. Further, we can also suppose $f(0)=0$. 
        For each $\epsilon \in (0,1)$ and each $x \in \epsilon \scU$, we have 
        \begin{equation}
            f(x) = f\pa{ \epsilon \frac{x}{\epsilon} + (1-\epsilon)0}  \leq \epsilon f\pa{ \frac{x}{\epsilon}} \leq \epsilon M
        \end{equation} 
        and
        since $0=\frac{x}{1+\epsilon}+\pa{1-\frac{1}{1+\epsilon} \pa{\frac{-x}{\epsilon}}}$, 
        \begin{equation}
            0=f(0)=f\pa{ \frac{x}{1+\epsilon} + \pa{1-\frac{1}{1+\epsilon}} \pa{\frac{-x}{\epsilon}}} \leq \frac{f(x)}{1+\epsilon}+\frac{\epsilon f\pa{-\frac{x}{\epsilon}}}{1+\epsilon}
        \end{equation} 
        so, since $\frac{-x}{\epsilon} \in \scU$, 
        \begin{equation} 
            -\epsilon M \leq -\epsilon f\pa{ \frac{x}{\epsilon}} \leq f(x)
        \end{equation}
        Hence, $|f(x)| \leq \epsilon M$ for $x \in \epsilon \scU$, and f is (weakly) continuous at 0. 
        Hence, it is sufficient to show that for any $y$ in the (weak) interior of $D(f)$, there is a (weak) neighborhood of y on which f is bounded from above. 
        To see this, let $y$ in the (weak) interior of $ D(f)$. 
        Since scalar multiplication is continuous, there is a $\rho >1$ such that $\rho y \in D(f)$. If $\scU_y=y+\pa{1-\frac{1}{\rho}}\scU$, then $x \in \scU_y$ can be written, for some $z \in \scU$, as
        \begin{equation}
            x=y+\pa{1-\frac{1}{\rho}}z=\frac{1}{\rho}(\rho y) + \pa{1-\frac{1}{\rho}}z
        \end{equation}
        Since f is convex, $D(f)$ is convex, and so $x \in D(f)$, implying $\scU_y \subset D(f)$. 
        Since f is a convex function, we also have that 
        \begin{equation}
            f(x) \leq \frac{1}{\rho} f(\rho y)+ \pa{1-\frac{1}{\rho}}f(x) \leq \frac{1}{\rho} f(\rho y) + \pa{ 1-\frac{1}{\rho}} M
        \end{equation}
        so that f is bounded on $\scU_y$ and is therefore continuous at y.
    \end{proof}
    \begin{proof}$(\impliedby)$
        This is obvious. 
    \end{proof} 
\end{thm} 
\begin{cor} Let $X$ be a locally convex, space and $f:X \to (-\infty,\infty]$ be LSC at some point in its effective domain. 
    \begin{enumerate}
        \item if $f$ is convex, then it is continuous on the interior of $D(f)$. 
        \item If $f$ is strictly convex, then it is continuous on X. 
    \end{enumerate} 
\end{cor}